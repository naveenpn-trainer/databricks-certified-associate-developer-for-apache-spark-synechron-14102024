# Introduction to Big Data and Hadoop 2.x

> Big Data refers to the data which is large, fast and complex type of structured, semi-structured and unstructured data generated from variety of different sources, which becomes difficult to store and process using a traditional processing system

**Disadvantage of RDBMS**

1. Designed to store only structured data.
2. Not designed for high velocity data **(Schema on write)**
3. Scalability : Vertical Scaling

**Challenges of Big Data**

1. Storage
2. Processing

## Distributed System

> A distributed system is a collection of computer systems that are physically separated but are linked together

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXecCxq9WBQpoiXoIjBlWdycKxC77UJsGPx9UGmO5M9xMOFPyqRkw_vwDOP6mMF0OkhOFUdCy805G8fdOk6cFWKdX9F-jhizS9i2iyrirVFh5oA0SnP5Lwd8hiKOCjS1Zj9URKxnGWqPpMgTQCOVsIAIXghZ?key=g4gNpbEJQ-HtUzqnN0b7Nw)



## Hadoop 2.x (Distributed Storage and Processing Framework)

> Apache Hadoop is a software framework that allows us to **store and process large datasets** in parallel and distributed fashion

## Components of Hadoop

1. Storage Layer : HDFS (Hadoop Distributed File System)
   - It is a primary storage component of Hadoop
   - It is based on Google File System
2. Resource Management Layer : YARN (Yet Another Resource Negotiator)
   - It is responsible for resource allocation and Job scheduling
3. Data Processing : MapReduce 
   - MR is a programming model to process the data in parallel in distributed fashion

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXf-cQCbkrMy-WtqsYk0sozgpSjOhIL-frGzgwv-97eIhC9FK_3GSMJpNTZNJ7wthZNNazfwMRSyPKDtlpE6QqfVy6DEVazgiOATxaE-b1WISP9zCzxhMbVgiSMCChQKfd2faKtMCZF1F2lN9x5UNWmU_Xvx?key=Lcjgu0sLjm8U8i3A_14gRg)

## Daemon Service

Hadoop provides 5 daemon services

1. NameNode
2. DataNode
3. SecondaryNameNode
4. ResourceManager
5. NodeManager

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdGEJ3GyHzEnZ78w4iGYY3Oq4iqDG8lCnkQvKbiF-KABMPuvmU-ix0gbYMaSDUXl8EQdlvZiyf1HXJhdt_Fe_ytR-XNkcMytXp7n3kKIt_wpD-_meAz3bnIRvF1h_Fuby6x1OzC4175lYKnicgZeyC8me0?key=Lcjgu0sLjm8U8i3A_14gRg)

## Hadoop Architecture

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUtm2N0r72PrJtG1tBocWVcDDTQcYwJmC0eM31SJFgZmd-J_IZUmxlsIDvtg0wgmMZJyaoRxeAG5T4YjVDscCG4DD8RGBYxPfHIpLJUTAMkCxMCFrKsCk4XWK6uu9zPTIsqTn1tUq4n08J1gg5RIjyBCuZ?key=Lcjgu0sLjm8U8i3A_14gRg)

## HDFS and Architecture

> HDFS is a **distributed** and **scalable file system** designed for storing very large files

**Distributed**

* In HDFS files are stored across multiple machines, HDFS splits the file into smaller pieces (Blocks)
* THe blocks size is 128 MB (configurable)

![image-20241014122510373](C:\MyTrainings\databricks-certified-associate-developer-for-apache-spark-synechron-14102024\imgs\01. Introduction to Big Data and Hadoop 2.x\image-20241014122510373.png)

